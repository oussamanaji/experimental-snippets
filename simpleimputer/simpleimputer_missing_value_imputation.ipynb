{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring SimpleImputer for Missing Value Imputation\n",
        "\n",
        "Author: Mohamed Oussama NAJI\n",
        "\n",
        "Date: Jan 29, 2024"
      ],
      "metadata": {
        "id": "jATh7G8Mxawd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, we will explore the SimpleImputer class from the sklearn.impute module for handling missing values in a dataset. We will use the heart disease dataset, which contains various demographic, behavioral, and medical features, to predict the risk of coronary heart disease (CHD) in patients.\n"
      ],
      "metadata": {
        "id": "0X0ZhyDnxeF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "1. [Data Loading and Exploration](#data-loading-exploration)\n",
        "   - [Loading the Dataset](#loading-dataset)\n",
        "   - [Dataset Information](#dataset-information)\n",
        "   - [Missing Value Analysis](#missing-value-analysis)\n",
        "2. [SimpleImputer](#simpleimputer)\n",
        "   - [Importing SimpleImputer](#importing-simpleimputer)\n",
        "   - [Creating SimpleImputer Object](#creating-simpleimputer-object)\n",
        "   - [Fitting and Transforming the Dataset](#fitting-transforming-dataset)\n",
        "   - [Visualizing Missing Values](#visualizing-missing-values)\n",
        "3. [Logistic Regression Models](#logistic-regression-models)\n",
        "   - [Model Without Imputation](#model-without-imputation)\n",
        "   - [Model With SimpleImputer Mean Strategy](#model-simpleimputer-mean)\n",
        "   - [Comparison of Accuracies](#comparison-accuracies)\n",
        "4. [Benchmarking with Random Forest](#benchmarking-random-forest)\n",
        "5. [Experiments with Different Strategies and Algorithms](#experiments-strategies-algorithms)\n",
        "   - [Strategies](#strategies)\n",
        "   - [Algorithms](#algorithms)\n",
        "   - [Experimental Results](#experimental-results)\n",
        "6. [Best Strategy for Random Forest](#best-strategy-random-forest)\n",
        "7. [Best Algorithm for Mean Strategy](#best-algorithm-mean-strategy)\n",
        "8. [Best Combination of Algorithm and Imputation Strategy](#best-combination-algorithm-strategy)\n",
        "9. [Conclusion](#conclusion)"
      ],
      "metadata": {
        "id": "q8Y_gd1uxg_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Exploration <a id=\"data-loading-exploration\"></a>\n"
      ],
      "metadata": {
        "id": "mSQ9_v8zxicj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Dataset <a id=\"loading-dataset\"></a>\n"
      ],
      "metadata": {
        "id": "R4wpEL85xjyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv(\"heart_disease.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "KTjBYjpGxnN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information <a id=\"dataset-information\"></a>\n"
      ],
      "metadata": {
        "id": "XeHsv9e4xoq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "qHTk3jJSxpwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Value Analysis <a id=\"missing-value-analysis\"></a>\n"
      ],
      "metadata": {
        "id": "qpFPbSqJxsxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df.columns)):\n",
        "    missing_data = df[df.columns[i]].isna().sum()\n",
        "    perc = missing_data / len(df) * 100\n",
        "    print(f'Feature {i+1} >> Missing entries: {missing_data}  |  Percentage: {round(perc, 2)}')\n"
      ],
      "metadata": {
        "id": "5XaS27cjxuPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df.isna(), cbar=False, cmap='viridis', yticklabels=False)"
      ],
      "metadata": {
        "id": "ucMjfn5dxwEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimpleImputer <a id=\"simpleimputer\"></a>"
      ],
      "metadata": {
        "id": "M-Wk65odxyIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing SimpleImputer <a id=\"importing-simpleimputer\"></a>\n"
      ],
      "metadata": {
        "id": "ph_khMDlxzLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "zmr7fV1dx0iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating SimpleImputer Object <a id=\"creating-simpleimputer-object\"></a>\n"
      ],
      "metadata": {
        "id": "u0coZClSx2mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(strategy='mean')"
      ],
      "metadata": {
        "id": "9n5X9pg2x4SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting and Transforming the Dataset <a id=\"fitting-transforming-dataset\"></a>\n"
      ],
      "metadata": {
        "id": "HHejKrWBx6b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.values\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "\n",
        "imputer.fit(X)\n",
        "\n",
        "X_transform = imputer.transform(X)"
      ],
      "metadata": {
        "id": "jqw97t2Vx7fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Missing Values <a id=\"visualizing-missing-values\"></a>\n"
      ],
      "metadata": {
        "id": "Gk9XuF5Gx-zZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df.isna(), cbar=False, cmap='viridis', yticklabels=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(X_transform.isna(), cbar=False, cmap='viridis', yticklabels=False)"
      ],
      "metadata": {
        "id": "66ADk066yAcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_transform = pd.DataFrame(data=X_transform)\n",
        "df_transform\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_transform.isna(), cbar=False, cmap='viridis', yticklabels=False)"
      ],
      "metadata": {
        "id": "g6-6PRJgyB52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Models <a id=\"logistic-regression-models\"></a>\n"
      ],
      "metadata": {
        "id": "ZeNyVPwfyD0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Without Imputation <a id=\"model-without-imputation\"></a>\n"
      ],
      "metadata": {
        "id": "6IwHBeT-yE_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X,y)"
      ],
      "metadata": {
        "id": "s0MUXRGryGju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model With SimpleImputer Mean Strategy <a id=\"model-simpleimputer-mean\"></a>\n"
      ],
      "metadata": {
        "id": "elBmtQIWyHqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "\n",
        "df = pd.read_csv(\"heart_disease.csv\")\n",
        "df = df.dropna()\n",
        "\n",
        "X = df[df.columns[:-1]]\n",
        "y = df[df.columns[-1]]\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "pipeline = Pipeline(steps=[('imputer', imputer), ('model', logistic_model)])\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores2 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv)\n",
        "\n",
        "print(f\"Mean Accuracy: {round(np.mean(scores2), 3)}  | Std: {round(np.std(scores2), 3)}\")"
      ],
      "metadata": {
        "id": "wfC-gTstyKQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison of Accuracies <a id=\"comparison-accuracies\"></a>\n"
      ],
      "metadata": {
        "id": "TDtiMNBzyMiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_accuracy1 = np.mean(scores)\n",
        "mean_accuracy2 = np.mean(scores2)\n",
        "\n",
        "if np.isclose(mean_accuracy1, mean_accuracy2, atol=1e-3):\n",
        "    print(\"Both methods have the same accuracy.\")\n",
        "else:\n",
        "    print(f\"Dropping missing values Mean Accuracy: {mean_accuracy1:.3f}\")\n",
        "    print(f\"SimpleImputer with Mean Strategy Mean Accuracy: {mean_accuracy2:.3f}\")"
      ],
      "metadata": {
        "id": "HK1t8YYMyOZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarking with Random Forest <a id=\"benchmarking-random-forest\"></a>\n"
      ],
      "metadata": {
        "id": "pjOrj6qJyPVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "random_forest_model = RandomForestClassifier()\n",
        "\n",
        "pipeline = Pipeline(steps=[('imputer', imputer), ('model', random_forest_model)])\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv)\n",
        "\n",
        "print(f\"Mean Accuracy: {round(np.mean(scores2), 3)}  | Std: {round(np.std(scores2), 3)}\")\n"
      ],
      "metadata": {
        "id": "tZeW0G4yySaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments with Different Strategies and Algorithms <a id=\"experiments-strategies-algorithms\"></a>\n"
      ],
      "metadata": {
        "id": "e91FYeweyVDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Strategies <a id=\"strategies\"></a>\n",
        "- Mean\n",
        "- Median\n",
        "- Most_frequent\n",
        "- Constant"
      ],
      "metadata": {
        "id": "ql1afELdyZ-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithms <a id=\"algorithms\"></a>\n",
        "- Logistic Regression\n",
        "- KNN\n",
        "- Random Forest\n",
        "- SVM\n",
        "- Any other algorithm of your choice"
      ],
      "metadata": {
        "id": "D9f3rVWcybXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimental Results <a id=\"experimental-results\"></a>\n"
      ],
      "metadata": {
        "id": "0iTEWbK3yd1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"heart_disease.csv\")\n",
        "X = df[df.columns[:-1]]\n",
        "y = df[df.columns[-1]]\n",
        "\n",
        "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
        "algorithms = [LogisticRegression(), KNeighborsClassifier(), RandomForestClassifier(), SVC(), DecisionTreeClassifier()]\n",
        "\n",
        "results = []\n",
        "\n",
        "for strategy in strategies:\n",
        "    for algorithm in algorithms:\n",
        "        if strategy == 'constant':\n",
        "            imputer = SimpleImputer(strategy=strategy, fill_value=0)\n",
        "        else:\n",
        "            imputer = SimpleImputer(strategy=strategy)\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('imputer', imputer),\n",
        "            ('model', algorithm)\n",
        "        ])\n",
        "\n",
        "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "        scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "        result = {\n",
        "            'strategy': strategy,\n",
        "            'algorithm': algorithm.__class__.__name__,\n",
        "            'mean_accuracy': np.mean(scores),\n",
        "            'std_accuracy': np.std(scores)\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "pkC-s7klygQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Strategy for Random Forest <a id=\"best-strategy-random-forest\"></a>\n"
      ],
      "metadata": {
        "id": "3W6H1NDYyif6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_results = [result for result in results if result['algorithm'] == 'RandomForestClassifier']\n",
        "\n",
        "best_strategy = max(rf_results, key=lambda x: x['mean_accuracy'])\n",
        "\n",
        "print(f\"The best imputation strategy for the Random Forest algorithm on this dataset is '{best_strategy['strategy']}' with a mean accuracy of {best_strategy['mean_accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "tLPCb-eaykpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Algorithm for Mean Strategy <a id=\"best-algorithm-mean-strategy\"></a>\n"
      ],
      "metadata": {
        "id": "yv_5rHhKymQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_results = [result for result in results if result['strategy'] == 'mean']\n",
        "\n",
        "algorithms_to_compare = ['LogisticRegression', 'RandomForestClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier']\n",
        "\n",
        "mean_results_filtered = [result for result in mean_results if result['algorithm'] in algorithms_to_compare]\n",
        "\n",
        "best_algorithm = max(mean_results_filtered, key=lambda x: x['mean_accuracy'])\n",
        "\n",
        "print(f\"The best algorithm for the 'mean' imputation strategy on this dataset is '{best_algorithm['algorithm']}' with a mean accuracy of {best_algorithm['mean_accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "nqrHfvJuyoG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Combination of Algorithm and Imputation Strategy <a id=\"best-combination-algorithm-strategy\"></a>\n"
      ],
      "metadata": {
        "id": "jVNi_qZjyprO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "algorithms_to_compare = ['LogisticRegression', 'RandomForestClassifier', 'KNeighborsClassifier']\n",
        "strategies_to_compare = ['mean', 'median', 'most_frequent', 'constant']\n",
        "\n",
        "filtered_results = [result for result in results if result['algorithm'] in algorithms_to_compare and result['strategy'] in strategies_to_compare]\n",
        "\n",
        "best_combination = max(filtered_results, key=lambda x: x['mean_accuracy'])\n",
        "\n",
        "print(f\"The best combination overall is '{best_combination['algorithm']}' algorithm with '{best_combination['strategy']}' imputation strategy, achieving a mean accuracy of {best_combination['mean_accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "cRe7WKGCyreH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion <a id=\"conclusion\"></a>\n",
        "\n",
        "In this notebook, we explored the SimpleImputer class from sklearn.impute for handling missing values in the heart disease dataset. We performed data exploration, analyzed missing values, and applied different imputation strategies using SimpleImputer.\n",
        "\n",
        "We built logistic regression models with and without imputation and compared their accuracies. We also benchmarked the performance using a random forest model with mean imputation strategy.\n",
        "\n",
        "Furthermore, we conducted experiments with different imputation strategies and algorithms to identify the best strategy for the random forest algorithm, the best algorithm for the mean imputation strategy, and the overall best combination of algorithm and imputation strategy.\n",
        "\n",
        "The experimental results provided insights into the effectiveness of different imputation strategies and algorithms for this specific dataset. It is important to note that the best strategy and algorithm may vary depending on the dataset and problem at hand.\n",
        "\n",
        "Overall, SimpleImputer proved to be a useful tool for handling missing values in the heart disease dataset, enabling us to build predictive models with improved accuracy."
      ],
      "metadata": {
        "id": "yELb9xEmyu85"
      }
    }
  ]
}