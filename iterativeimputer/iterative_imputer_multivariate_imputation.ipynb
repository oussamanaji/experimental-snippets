{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Iterative Imputer for Multivariate Imputation\n",
        "\n",
        "Author: Mohamed Oussama NAJI\n",
        "\n",
        "Date: Jan 29, 2024"
      ],
      "metadata": {
        "id": "JV1US_dFy_di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, we will explore the usage of Iterative Imputer for multivariate imputation of missing values in a dataset. Iterative Imputer is a technique that substitutes missing values as a function of other features. We will use the heart disease dataset, which contains various demographic, behavioral, and medical features, to predict the risk of coronary heart disease (CHD) in patients.\n"
      ],
      "metadata": {
        "id": "dOIfEBlVzDKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "1. [Data Loading and Exploration](#data-loading-exploration)\n",
        "   - [Loading the Dataset](#loading-dataset)\n",
        "   - [Dataset Information](#dataset-information)\n",
        "   - [Missing Value Analysis](#missing-value-analysis)\n",
        "   - [Visualizing Missing Values](#visualizing-missing-values)\n",
        "2. [Iterative Imputer](#iterative-imputer)\n",
        "   - [Importing Iterative Imputer](#importing-iterative-imputer)\n",
        "   - [Creating Iterative Imputer Object](#creating-iterative-imputer-object)\n",
        "   - [Fitting and Transforming the Dataset](#fitting-transforming-dataset)\n",
        "   - [Visualizing Imputed Data](#visualizing-imputed-data)\n",
        "3. [Logistic Regression Models](#logistic-regression-models)\n",
        "   - [Model Without Imputation](#model-without-imputation)\n",
        "   - [Model With Iterative Imputer](#model-iterative-imputer)\n",
        "   - [Comparison of Accuracies](#comparison-accuracies)\n",
        "4. [Iterative Imputer with Random Forest](#iterative-imputer-random-forest)\n",
        "5. [Experiments with Different Imputation Methods and Algorithms](#experiments-imputation-algorithms)\n",
        "   - [Imputation Methods](#imputation-methods)\n",
        "   - [Algorithms](#algorithms)\n",
        "   - [Experimental Results](#experimental-results)\n",
        "6. [Best Strategy for Random Forest](#best-strategy-random-forest)\n",
        "7. [Best Algorithm for Iterative Imputer](#best-algorithm-iterative-imputer)\n",
        "8. [Best Combination of Algorithm and Imputation Strategy](#best-combination-algorithm-strategy)\n",
        "9. [Conclusion](#conclusion)"
      ],
      "metadata": {
        "id": "9qvAtYF3zHgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Exploration <a id=\"data-loading-exploration\"></a>\n"
      ],
      "metadata": {
        "id": "Ir7_FHTdzIxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yKWVHU9ezJ49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Dataset <a id=\"loading-dataset\"></a>\n"
      ],
      "metadata": {
        "id": "4yeVwJ-1zJ7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv(\"heart_disease.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "t_bqJCr0zLvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information <a id=\"dataset-information\"></a>\n"
      ],
      "metadata": {
        "id": "i-GNeXi9zNSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "7p8iUajLzOVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Value Analysis <a id=\"missing-value-analysis\"></a>\n"
      ],
      "metadata": {
        "id": "J5BRIhfszQM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df.columns)):\n",
        "    missing_data = df[df.columns[i]].isna().sum()\n",
        "    perc = missing_data / len(df) * 100\n",
        "    print(f'Feature {i+1} >> Missing entries: {missing_data}  |  Percentage: {round(perc, 2)}')"
      ],
      "metadata": {
        "id": "hVHvq4eAzSdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Missing Values <a id=\"visualizing-missing-values\"></a>\n"
      ],
      "metadata": {
        "id": "Kj_TRnoQzUoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df.isna(), cbar=False, cmap='viridis', yticklabels=False)"
      ],
      "metadata": {
        "id": "vHrKw_NWzWNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterative Imputer <a id=\"iterative-imputer\"></a>\n"
      ],
      "metadata": {
        "id": "1jnzZTuLzXys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Iterative Imputer <a id=\"importing-iterative-imputer\"></a>"
      ],
      "metadata": {
        "id": "k0TrdQZYzjOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer"
      ],
      "metadata": {
        "id": "LFUiokjVzlA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Iterative Imputer Object <a id=\"creating-iterative-imputer-object\"></a>\n"
      ],
      "metadata": {
        "id": "oFielk3jzmYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = IterativeImputer(max_iter=10, random_state=0)"
      ],
      "metadata": {
        "id": "ezOW31k7znzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting and Transforming the Dataset <a id=\"fitting-transforming-dataset\"></a>\n"
      ],
      "metadata": {
        "id": "jOMQBzWkzpJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.values\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "\n",
        "imputer.fit(X)\n",
        "X_transform = imputer.transform(X)"
      ],
      "metadata": {
        "id": "UF8ebHFyzrBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Imputed Data <a id=\"visualizing-imputed-data\"></a>\n"
      ],
      "metadata": {
        "id": "7UOtJ4NkzsU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Missing cells: {sum(np.isnan(X).flatten())}\")\n",
        "print(f\"Missing cells: {sum(np.isnan(X_transform).flatten())}\")\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df.isna(), cbar=False, cmap='viridis', yticklabels=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(X_transform.isna(), cbar=False, cmap='viridis', yticklabels=False)\n",
        "\n",
        "df_transform = pd.DataFrame(data=X_transform)\n",
        "df_transform\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_transform.isna(), cbar=False, cmap='viridis', yticklabels=False)"
      ],
      "metadata": {
        "id": "9KzIN-NZzvbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Models <a id=\"logistic-regression-models\"></a>\n"
      ],
      "metadata": {
        "id": "73uhG4Sfz9J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Without Imputation <a id=\"model-without-imputation\"></a>\n"
      ],
      "metadata": {
        "id": "6I4hyY9v0Im4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"heart_disease.csv\")\n",
        "X = df[df.columns[:-1]]\n",
        "y = df[df.columns[-1]]\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "DLEZWT5a0KYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model With Iterative Imputer <a id=\"model-iterative-imputer\"></a>\n"
      ],
      "metadata": {
        "id": "zpUAbTmp0Lo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "\n",
        "df = pd.read_csv(\"heart_disease.csv\")\n",
        "X = df[df.columns[:-1]]\n",
        "y = df[df.columns[-1]]\n",
        "\n",
        "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "model = LogisticRegression()\n",
        "\n",
        "pipeline = Pipeline([('impute', imputer), ('model', model)])\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores2 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "print(f\"Mean Accuracy: {round(np.mean(scores2), 3)}  | Std: {round(np.std(scores2), 3)}\")"
      ],
      "metadata": {
        "id": "4R8NAQbn0N45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison of Accuracies <a id=\"comparison-accuracies\"></a>"
      ],
      "metadata": {
        "id": "CeFuFlUJ0Pgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_accuracy1 = np.mean(scores)  # Accuracy for dropping missing values method\n",
        "mean_accuracy2 = np.mean(scores2)  # Accuracy for iterative imputer with mean strategy\n",
        "\n",
        "if np.isclose(mean_accuracy1, mean_accuracy2, atol=1e-3):\n",
        "    print(\"Both methods have the same accuracy.\")\n",
        "elif mean_accuracy1 > mean_accuracy2:\n",
        "    print(f\"Dropping missing values method is better, with Mean Accuracy: {mean_accuracy1:.3f}\")\n",
        "else:\n",
        "    print(f\"Iterative Imputer with Mean Strategy method is better, with Mean Accuracy: {mean_accuracy2:.3f}\")"
      ],
      "metadata": {
        "id": "wPjxv6TP0SDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterative Imputer with Random Forest <a id=\"iterative-imputer-random-forest\"></a>\n"
      ],
      "metadata": {
        "id": "fM1vexcf0UX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "\n",
        "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "pipeline = Pipeline([('impute', imputer), ('model', model)])\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "print(f\"Mean Accuracy: {round(np.mean(scores), 3)}  | Std: {round(np.std(scores), 3)}\")"
      ],
      "metadata": {
        "id": "GGjLwayg0WfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments with Different Imputation Methods and Algorithms <a id=\"experiments-imputation-algorithms\"></a>\n"
      ],
      "metadata": {
        "id": "tNrlJzEm0YjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imputation Methods <a id=\"imputation-methods\"></a>\n",
        "- Mean\n",
        "- Median\n",
        "- Most_frequent\n",
        "- Constant\n",
        "- IterativeImputer"
      ],
      "metadata": {
        "id": "4qVpkcMh0akB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithms <a id=\"algorithms\"></a>\n",
        "- Logistic Regression\n",
        "- KNN\n",
        "- Random Forest\n",
        "- SVM\n",
        "- Any other algorithm of your choice"
      ],
      "metadata": {
        "id": "gbFZPpN20cNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimental Results <a id=\"experimental-results\"></a>\n"
      ],
      "metadata": {
        "id": "TfftN_5r0dYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer, IterativeImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "strategies = ['mean', 'median', 'most_frequent', 'constant', 'iterative']\n",
        "algorithms = [LogisticRegression(), KNeighborsClassifier(), RandomForestClassifier(), SVC(), GradientBoostingClassifier()]\n",
        "\n",
        "results = []\n",
        "\n",
        "for strategy in strategies:\n",
        "    for model in algorithms:\n",
        "        if strategy == 'iterative':\n",
        "            imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "        elif strategy == 'constant':\n",
        "            imputer = SimpleImputer(strategy=strategy, fill_value=0)\n",
        "        else:\n",
        "            imputer = SimpleImputer(strategy=strategy)\n",
        "\n",
        "        pipeline = Pipeline([('impute', imputer), ('model', model)])\n",
        "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "        scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "        results.append((strategy, model.__class__.__name__, scores))\n",
        "\n",
        "for result in results:\n",
        "    strategy, model_name, scores = result\n",
        "    mean_accuracy = np.mean(scores)\n",
        "    max_accuracy = np.max(scores)\n",
        "    print(f\"Strategy: {strategy}, Model: {model_name} >> Accuracy: {mean_accuracy:.3f} | Max accuracy: {max_accuracy:.3f}\")\n"
      ],
      "metadata": {
        "id": "goO75SuW0f5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Strategy for Random Forest <a id=\"best-strategy-random-forest\"></a>\n"
      ],
      "metadata": {
        "id": "_eKmqZl10hJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_results = [result for result in results if result[1] == 'RandomForestClassifier']\n",
        "\n",
        "best_strategy_rf = max(rf_results, key=lambda x: np.mean(x[2]))\n",
        "\n",
        "print(f\"The best imputation strategy for the Random Forest algorithm on this dataset is '{best_strategy_rf[0]}' with a mean accuracy of {np.mean(best_strategy_rf[2]):.3f}\")"
      ],
      "metadata": {
        "id": "9QU8QFP40ik-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Algorithm for Iterative Imputer <a id=\"best-algorithm-iterative-imputer\"></a>\n"
      ],
      "metadata": {
        "id": "nV5m85cs0kMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterative_imputer_results = [result for result in results if result[0] == 'iterative']\n",
        "\n",
        "algorithms_to_compare = ['LogisticRegression', 'RandomForestClassifier', 'KNeighborsClassifier', 'GradientBoostingClassifier']\n",
        "\n",
        "iterative_imputer_results_filtered = [result for result in iterative_imputer_results if result[1] in algorithms_to_compare]\n",
        "\n",
        "best_algorithm_iterative = max(iterative_imputer_results_filtered, key=lambda x: np.mean(x[2]))\n",
        "\n",
        "print(f\"The best algorithm for the 'IterativeImputer' strategy on this dataset is '{best_algorithm_iterative[1]}' with a mean accuracy of {np.mean(best_algorithm_iterative[2]):.3f}\")"
      ],
      "metadata": {
        "id": "FBBAo1t70nJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Combination of Algorithm and Imputation Strategy <a id=\"best-combination-algorithm-strategy\"></a>\n"
      ],
      "metadata": {
        "id": "zoO3ZvXI0pDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_overall_combination = max(results, key=lambda x: np.mean(x[2]))\n",
        "\n",
        "best_strategy = best_overall_combination[0]\n",
        "best_algorithm = best_overall_combination[1]\n",
        "best_mean_accuracy = np.mean(best_overall_combination[2])\n",
        "\n",
        "print(f\"The best combination overall is using '{best_strategy}' strategy with '{best_algorithm}' algorithm, achieving a mean accuracy of {best_mean_accuracy:.3f}\")\n"
      ],
      "metadata": {
        "id": "gaZhGOHm0rk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion <a id=\"conclusion\"></a>\n",
        "\n",
        "In this notebook, we explored the usage of Iterative Imputer for multivariate imputation of missing values in the heart disease dataset. We performed data exploration, analyzed missing values, and applied Iterative Imputer to impute the missing values based on other features.\n",
        "\n",
        "We built logistic regression models with and without imputation and compared their accuracies. We also experimented with different imputation methods and algorithms to identify the best strategy for the Random Forest algorithm, the best algorithm for the Iterative Imputer strategy, and the overall best combination of algorithm and imputation strategy.\n",
        "\n",
        "The experimental results showed that Iterative Imputer can be an effective technique for handling missing values in this dataset, often leading to improved model performance compared to dropping missing values.\n",
        "\n",
        "However, it is important to note that the choice of imputation method and algorithm may vary depending on the specific dataset and problem at hand. It is recommended to evaluate different imputation strategies and algorithms for each specific use case to determine the most suitable approach.\n",
        "\n",
        "Overall, Iterative Imputer demonstrated its potential as a valuable tool for multivariate imputation, enabling the development of more robust predictive models in the presence of missing data."
      ],
      "metadata": {
        "id": "CNCXYIfa0zjx"
      }
    }
  ]
}